{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ET2MyQweDd_m",
        "outputId": "737bdebb-0103-4d16-9d99-805240e58f82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "!pip install PyPDF2\n",
        "import PyPDF2\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# define a function to extract text from PDF resumes\n",
        "def extract_text_from_pdf(file_path):\n",
        "    pdf_file = open(file_path, 'rb')\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "    resume_text = ''\n",
        "    for page in range(len(pdf_reader.pages)):\n",
        "        resume_text += pdf_reader.pages[page].extract_text()\n",
        "    resume_text = resume_text.lower()\n",
        "    resume_text = resume_text.replace('[^\\w\\s]','')\n",
        "    resume_text = resume_text.replace('\\d+', '')\n",
        "    return resume_text\n",
        "\n",
        "# define the path to the directory containing PDF resumes\n",
        "directory_path = '/content/drive/MyDrive/Resumes'\n",
        "\n",
        "# loop through the PDF resumes in the directory and extract their text\n",
        "resume_texts = []\n",
        "for file_name in os.listdir(directory_path):\n",
        "    if file_name.endswith('.pdf'):\n",
        "        file_path = os.path.join(directory_path, file_name)\n",
        "        resume_text = extract_text_from_pdf(file_path)\n",
        "        resume_texts.append(resume_text)\n",
        "\n",
        "# create a pandas dataframe with the preprocessed text\n",
        "resume_data = pd.DataFrame({'text': resume_texts, 'label': ['match']*len(resume_texts)})\n",
        "\n",
        "# extract features using TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(resume_data['text'])\n",
        "\n",
        "# split the data into training and testing sets\n",
        "y = resume_data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# train the SVM model\n",
        "svm_model = SVC(kernel='linear', probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# evaluate the model on the test set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "kj2FVwJHCEVh",
        "outputId": "b3929edb-adca-4c7d-e994-bf9f8edefbab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:PyPDF2.generic._data_structures:Multiple definitions in dictionary at byte 0x223 for key /TRP1\n",
            "WARNING:PyPDF2.generic._data_structures:Multiple definitions in dictionary at byte 0x225 for key /ExtGState\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-391c90b9fc66>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# train the SVM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0msvm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# evaluate the model on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         sample_weight = np.asarray(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    750\u001b[0m                 \u001b[0;34m\"The number of classes has to be greater than one; got %d class\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "!pip install PyPDF2\n",
        "import PyPDF2\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# define a function to extract text from PDF resumes\n",
        "def extract_text_from_pdf(file_path):\n",
        "    pdf_file = open(file_path, 'rb')\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "    resume_text = ''\n",
        "    for page in range(len(pdf_reader.pages)):\n",
        "        resume_text += pdf_reader.pages[page].extract_text()\n",
        "    resume_text = resume_text.lower()\n",
        "    resume_text = resume_text.replace('[^\\w\\s]','')\n",
        "    resume_text = resume_text.replace('\\d+', '')\n",
        "    return resume_text\n",
        "\n",
        "# define the path to the directory containing PDF resumes\n",
        "directory_path = '/content/drive/MyDrive/Resumes'\n",
        "\n",
        "# loop through the PDF resumes in the directory and extract their text\n",
        "resume_texts = []\n",
        "resume_labels = []\n",
        "for file_name in os.listdir(directory_path):\n",
        "    if file_name.endswith('.pdf'):\n",
        "        file_path = os.path.join(directory_path, file_name)\n",
        "        resume_text = extract_text_from_pdf(file_path)\n",
        "        resume_texts.append(resume_text)\n",
        "        if 'no_match' in file_name:\n",
        "            resume_labels.append('no_match')\n",
        "        else:\n",
        "            resume_labels.append('match')\n",
        "\n",
        "# create a pandas dataframe with the preprocessed text and labels\n",
        "resume_data = pd.DataFrame({'text': resume_texts, 'label': resume_labels})\n",
        "\n",
        "# extract features using TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(resume_data['text'])\n",
        "\n",
        "# split the data into training and testing sets\n",
        "y = resume_data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# train the SVM model\n",
        "svm_model = SVC(kernel='linear', probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# evaluate the model on the test set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "PZjptOT3FAEe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}