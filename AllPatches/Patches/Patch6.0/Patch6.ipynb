{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "!pip install PyMuPDF\n",
        "!pip install --upgrade PyPDF2\n",
        "import os\n",
        "import nltk\n",
        "import PyPDF2\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def extract_skills_from_text(text):\n",
        "    # Extract the skills section from the text\n",
        "    skills_start_pattern = r\"(?i)\\bSkills\\b\"\n",
        "    skills_end_pattern = r\"(?i)\\bEducation\\b|\\bExperience\\b|\\bWork\\b|\\bSummary\\b\"\n",
        "    skills_section = re.search(skills_start_pattern, text)\n",
        "    if skills_section:\n",
        "        text = text[skills_section.start():]\n",
        "        end_match = re.search(skills_end_pattern, text)\n",
        "        if end_match:\n",
        "            text = text[:end_match.start()]\n",
        "    return text\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "        return text\n",
        "\n",
        "def calculate_similarity(resume1, resume2):\n",
        "    # Preprocess resumes\n",
        "    stop_words = stopwords.words('english')\n",
        "    tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
        "    resume_list = [resume1, resume2]\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(resume_list)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity_score = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "# Path to the job listing resume PDF\n",
        "job_listing_resume_path = \"/content/Accountant.pdf\"\n",
        "\n",
        "# Resumes folder path\n",
        "resumes_folder = \"/content/drive/MyDrive/Accounting\"\n",
        "\n",
        "# Extract skills from the job listing resume\n",
        "job_listing_resume = extract_text_from_pdf(job_listing_resume_path)\n",
        "job_listing_resume_skills = extract_skills_from_text(job_listing_resume)\n",
        "\n",
        "# List to store similarity results\n",
        "similarity_results = []\n",
        "\n",
        "# Process each resume in the folder\n",
        "for filename in os.listdir(resumes_folder):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        # Read worker's resume\n",
        "        resume_file = os.path.join(resumes_folder, filename)\n",
        "        worker_resume = extract_text_from_pdf(resume_file)\n",
        "        worker_resume_skills = extract_skills_from_text(worker_resume)\n",
        "\n",
        "        # Calculate similarity\n",
        "        similarity = calculate_similarity(job_listing_resume_skills, worker_resume_skills)\n",
        "\n",
        "        # Add the filename and similarity score to the results list\n",
        "        similarity_results.append((filename, similarity))\n",
        "\n",
        "# Sort the results in descending order based on similarity score\n",
        "similarity_results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Print the results with 2 decimal places\n",
        "for result in similarity_results:\n",
        "    filename, similarity = result\n",
        "    similarity_rounded = round(similarity, 4)\n",
        "    similarity_rounded = similarity_rounded * 100\n",
        "    print(f\"{filename} - {similarity_rounded:.2f}% similarity\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_SBi0ufERK-",
        "outputId": "1dc428ea-7c67-4861-827d-ccd29c5b3fe6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.22.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chad_Gibbons_02.pdf - 23.21% similarity\n",
            "Howard_Ong_01.pdf - 14.08% similarity\n",
            "Howard_Ong_02.pdf - 8.59% similarity\n",
            "Marceline_Anderson_04.pdf - 8.16% similarity\n",
            "Rachelle_Beaudry_04.pdf - 7.35% similarity\n",
            "Claudia_Alves_04.pdf - 6.51% similarity\n",
            "Juliana_Silva_04.pdf - 6.51% similarity\n",
            "Donna_Stroupe_01.pdf - 5.66% similarity\n",
            "Harper_Russo_03.pdf - 5.48% similarity\n",
            "Samira_Hadid_02.pdf - 4.86% similarity\n",
            "Harper_Russo_07.pdf - 4.78% similarity\n",
            "Greta_Mae_Evans_01.pdf - 4.06% similarity\n",
            "Hannah_Morales_01.pdf - 4.01% similarity\n",
            "Korina_Villanueva_05.pdf - 3.58% similarity\n",
            "Korina_Villanueva_06.pdf - 3.14% similarity\n",
            "Jonathan_Patterson_03.pdf - 2.98% similarity\n",
            "Marceline_Anderson_08.pdf - 2.56% similarity\n",
            "Korina_Villanueva_02.pdf - 2.52% similarity\n",
            "Samira_Hadid_01.pdf - 1.68% similarity\n",
            "Olivia_Wilson_10.pdf - 1.63% similarity\n",
            "Helene_Paquet_01.pdf - 0.68% similarity\n",
            "Korina_Villanueva_08.pdf - 0.45% similarity\n",
            "Juliana_Silva_05.pdf - 0.21% similarity\n",
            "Isabel_Mercado_01.pdf - 0.20% similarity\n",
            "Bailey_Dupont.pdf - 0.00% similarity\n",
            "Aaron_Loeb_04.pdf - 0.00% similarity\n",
            "Adeline_Palmerston_04.pdf - 0.00% similarity\n"
          ]
        }
      ]
    }
  ]
}